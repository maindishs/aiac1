{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1sthomework.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0ioSey8BCYCHXhVlRM2BY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maindishs/aiac1/blob/master/1sthomework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RCksMeRvLfE",
        "colab_type": "text"
      },
      "source": [
        "목차\n",
        "=====\n",
        "인공지능 기술 사용 사례\n",
        "---\n",
        "> 인공지능(AI, Artificial Intelligence)’입니다. 인공지능은 인간의 학습 능력, 추론 능력, 지각 능력, 이해력 등을 컴퓨터 프로그램으로 실현한 기술\n",
        "\n",
        "* 언어\n",
        "* 음성\n",
        "* 이미지\n",
        "* 자율주행\n",
        "> + 각 분야의 제품 또는 서비스 분석   \n",
        "+ 학습목표 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGpUBn7bbtum",
        "colab_type": "text"
      },
      "source": [
        " **1.언어 : 구글 번역기**\n",
        "===\n",
        "구문 기반 기계번역(PBMT) -> 구글 신경망 기계번역(GNMT) -> + 제로샷 번역\n",
        "---\n",
        "# 구문 기반 기계번역(PBMT)\n",
        "\n",
        "> 2007년 구글이 처음으로 번역기를 출시했을 때는 __'구문 기반' 기계번역(PBMT)알고리즘을__ 사용한 기술을 사용했었다. \n",
        "\n",
        "* 구문 기반 기계번역은 문장을 단어와 구 단위로 쪼개서 하나하나 개별적으로 번역하는 방식이다.\n",
        "\n",
        "  * 이 기술은 자주 사용되는 단어 중심의 번역 방식이다 보니 번역된 문장이 매끄럽지 못했다.\n",
        "\n",
        "   * 단순히 단어를 나열하는 수준의 번역을 제공해 오류가 많다는 지적이 있어왔다.   \n",
        "\n",
        "# 구글 신경망 기계번역(GNMT)   \n",
        "\n",
        ">2016년 9월 __'구글 신경망 기계번역(GNMT)'__ 기술을 처음으로 선보였다.   \n",
        "\n",
        "* 구글은 좀 더 인간의 언어와 비슷한 구조의 자연스러운 번역 서비스를 제공하기 위해 머신러닝을 도입한 인공신경망 기계번역 을 자체 개발했다.\n",
        "\n",
        "  * 인공신경망 기계번역은 단어를 개별적으로 번역하는 구문 기반과 달리, 전체 문장을 하나의 번역 단위로 간주해 한꺼번에 번역한다.   \n",
        "\n",
        "   * 이는 문장 전체의 맥락을 먼저 파악한 후 어순, 의미, 문맥별 의미 차이 등을 반영해 가장 적합한 문장으로 재배열하는 방식이다.   \n",
        "\n",
        ">>이로 인해 인공신경망 기계번역은 구문기반 기계번역보다 자연스러운 문장을 제공할 수 있으며, 전체 텍스트의 가독성 또한 향상됐다.\n",
        "\n",
        "\n",
        "# 제로샷 번역(Zero-Shot Translation)   \n",
        "\n",
        " * 구글은 더 다양한 언어에 신경망 기계번역 기술을 지원하기 위해 단일 시스템에서  여러 언어 간 번역이 가능하도록 하는 방식   \n",
        "\n",
        "  * 이는 다중 언어 트레이닝을 통해 실제 테스트하지 않은 여러 언어 조합의 번역도 데이터를 활용해서 가능하게 하는 기술이다   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ">>일단 이미지 삽입은 나중에\n",
        "\n",
        "Link: [Google][googlelink]\n",
        "\n",
        "[googlelink]: https://google.com \"Go google\"\n",
        "\n",
        "<http://example.com/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXrr9DpU9iRK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "초기 자동번역 또는 기계번역이라고 불리는 기술은 크게__규칙기반__(RBMT, Rule-Based Machine Translation)과 __통계기반__(SMT, Statistical Machine Translation), 이를 합한 __하이브리드__(RBMT+SMT) 기반으로 구분된다.\n",
        "+ RBMT =~ '기호주의 인공지능' :   \n",
        " > 문법 규칙이 아닐 경우에는 번역 오류가 상당히 높다.   \n",
        " > 개발자가 일일히 규칙을 입력 해야한다는 문제점이 있다.   \n",
        "\n",
        "* SMT :   \n",
        "> 통계기반은 딥러닝과 빅데이터를 활용하기 때문에 언어 데이터베이스 확보가 중요하다   \n",
        "> 단어와 구(Phrase) 형식으로 각각 나눠 번역해 조합하는 방식   \n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzo1ut0DlF4V",
        "colab_type": "text"
      },
      "source": [
        ">>__신경망 번역 방식의 원리__\n",
        "\n",
        "입체 공간이 있다고 가정하자. 먼저 ‘먹다’라는 단어를 공간에 띄운다. 그리고 그 근처에 ‘먹었다’, ‘먹을 거다’, ‘먹고 싶다’ 등 ‘먹다’라는 단어와 관계가 있는 단어들을 유사한 공간에 둔다. 이 ‘먹다’라는 단어에는 다양한 차원이 있을 수 있다. 이 차원에 따라 또 다른 단어들과 관계를 맺을 수 있다. 예컨대 치킨, 피자, 케이크 등 ‘먹다’와 함께 쓰일 수 있는 단어들이 또 ‘먹다’와 나름의 관계를 맺고 공간상에 위치할 수 있다. 이렇게 단어나 구 등이 공간에서 관계를 맺으며 맵핑된다. 이때 가지는 벡터값을 ‘단어 표현’이라고 한다. 번역기에 사용되는 단어는 200차원의 단어 표현 값으로 변환된다.\n",
        "\n",
        "‘나는’, ‘사과를’, ‘먹는다’, ‘I’, ‘eat’, ‘apple’은 각각 단어 표현 값으로 변환된다. 그리고 이 단어 표현들을 이어가며 번역하려는 문장에서 결과 문장으로 이어주는 최적의 가중치(Weight parameter)들을 찾아 행렬 곱으로 이어가 벡터를 구해가는 방식이다.\n",
        "\n",
        "\n",
        "여기서 번역하려는 문장과 결과 문장을 컴퓨터에 주고, 결과 문장이 나오게 하는 값을 찾아내는 최적의 가중치(WP)를 반복적인 기계학습을 통해 자동으로 컴퓨터가 학습한다. 번역은 EOS(문장의 끝, End Of Sentence)값이 가장 높아지면 끝난다. 번역 언어가 달라질 때마다 가중치 값이 바뀐다. 이처럼 인공신경망 기계번역은 입력 문장과 출력 문장을 하나의 쌍으로 두고, 최적의 답을 찾는 중간 값을 학습한다.\n",
        "\n",
        "\n",
        "인공신경망 기계번역 방식은 통계적 기계번역보다 번역 시스템이 단순하다는 장점을 가진다. 입력 문장과 출력 문장만 있으면 알아서 학습하게끔 유도하기 때문에 구조 자체가 그렇게 어렵지 않기 때문이다.\n",
        "\n",
        "\n",
        "인공신경망 기계번역은 확장하기 쉽고 다양한 구조를 채택할 수 있다는 것도 장점이다. 다만 학습 시간이 다소 오래 걸릴 수는 있다. 이 문제를 해결하기 위해 병렬처리 등의 방식을 사용한다. 그러나 인공신경망 기계번역은 아직 초창기이기 때문에 많은 문제점과 가능성이 병존하고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eeUBMDumIig",
        "colab_type": "text"
      },
      "source": [
        "**2.음성  : 스마트 스피커 SKT 'NUGU'**\n",
        "===\n",
        "SKT 음성 인식 기술\n",
        "---\n",
        "2014년부터 상용화 시작\n",
        "음성인식 기술 구성\n",
        "음성인식 기술은 크게 모델을 학습하는 단계, 학습된 모델을 이용하여 인식하는 단계로 구분되고,\n",
        "이 중 음향, 언어 모델을 학습할 수 있는 기술이 핵심   \n",
        "\n",
        " 통합모델(wFST) 기술\n",
        "- 문장 단위 학습에 최적화되어 속도와 인식률 향상\n",
        "- 향후 대용량 연속 어휘, 즉 자연어 음성인식을 위한 핵심 기술   \n",
        "\n",
        " 모델링 기술 및 데이터\n",
        "- 음향모델 : 입력 신호와 음소의 유사도\n",
        "- 언어모델 : 단어간 확률 관계 그래프\n",
        "- 발음사전 : 단어의 발성 정보 저장\n",
        "    예) 선릉 : 설릉(ㅅ ㅓ ㄹ ㄹ ㅡ ㅇ), 선능(ㅅ ㅓ ㄴ ㄴ ㅡ ㅇ)\n",
        "\n",
        "    ㄴㄹㄴㅇ이게 뭐여?   \n",
        "\n",
        "음성인식 기술 구성 - 자체 기술 개발\n",
        "속도, 성능을 향상시킨 wFST, 컴퓨팅 파워의 향상에 기반한 DNN 기술 적용\n",
        "\n",
        "1.전처리   \n",
        "\n",
        "Feature\n",
        ">HLDA, STC, Equalization / Wiener, Kalman Filter / Model Space \n",
        "Neural Net\n",
        ">Bottleneck Feature\n",
        "\n",
        "2.학습   \n",
        "\n",
        "Discriminative Training\n",
        ">MPE, fMPE   \n",
        ">MCE, MMI   \n",
        "\n",
        "Big LM\n",
        ">Distributed Modeling, Long Span LM   \n",
        "\n",
        "Deep Neural Network   \n",
        ">DNN based Acoustic Modeling Training   \n",
        "\n",
        "3.인식   \n",
        "\n",
        "Dynamic Network   \n",
        ">FSN   \n",
        ">Lexical Tree   \n",
        "\n",
        "Static Network   \n",
        ">wFST (weighted Finite State Transducer)\n",
        "\n",
        "\n",
        "음성인식 기술 구성 - Neural Network 기반 언어모델링 (NN-LM)\n",
        ">Neural Net기반 언어모델에서는 아직까지 음향모델만큼 큰 성능향상을 이루지는 못함   \n",
        "\n",
        "음성인식 기술 구성 – Personalized Language Model (PLM)   \n",
        "> 개인화된 어휘가 사용될 위치를 사전에 class 형태로 모델링    \n",
        "\n",
        "음성인식 기술 구성 - Sequence to Sequence Learning, CTC \n",
        ">RNN-LSTM을 음절 기반의 띄어쓰기 모델에 확장 적용함으로써 성능 향상.\n",
        "발음열 생성기술에 CTC(Connectionist Temporal Classification) 적용 등 다양한 영역에서 DNN적용을 시도 중   \n",
        "\n",
        ">>LSTM 언어모델링\n",
        ">>>문장을 구성하는 단어 sequence에 대해\n",
        "다음 단어의 sequence를 target으로 학습   \n",
        "\n",
        ">>LSTM 띄어쓰기 모델\n",
        ">>>한글 corpus의 음절 sequence에 대해\n",
        "각 음절 별 띄어쓰기 및 문장부호를 target으로 학습\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQVve84QoPmk",
        "colab_type": "text"
      },
      "source": [
        "**+네이버 클로바**\n",
        "===\n",
        "네이버가 개발한 음성인식 인공지능(AI) 엔진 'NEST'\n",
        "---\n",
        "NEST는 뉴스·통화·미디어 음성 파일을 텍스트로 변환하는 데 최적화됐다.\n",
        "\n",
        "음향·언어모델 통합 학습하는 엔드투엔드 방식 적용\n",
        " \n",
        ">엔드투엔드는 음향 모델(AM)과 언어 모델(LM)을 따로 학습하지 않고 통합해 학습하는 방식이다.   \n",
        "\n",
        ">AM과 LM을 별도로 학습하는 기존 음성정보의 텍스트 변환 기술(STT)과는 차별화된다.   \n",
        "\n",
        ">AM은 발음 정보를, LM은 어휘들의 변형 및 관계를 다루는데, 기존 STT에서 AM은 음성과 정답 데이터가 잘 정리된 데이터가 필요하고 LM은 복잡한 표현을 미리 학습해야 좋은 결과를 낼 수 있는 부담이 따랐다.   \n",
        "\n",
        ">이에 한 리더는 음성 정보와 정답 텍스트 정보를 한꺼번에 학습하는 엔드투엔드 방식을 택했다.   \n",
        "\n",
        ">데이터를 정제하는 부담이 줄었고 AI 엔진이 학습해야 하는 절대적인 양도 감소했다.   \n",
        "\n",
        ">구어체 표현이나 비문에 일일이 미리 대응해두지 않아도 원래 음성과 유사한 인식 결과를 낼 수 있게 됐다.   \n",
        "\n",
        "NEST 개발에는 네이버가 보유한 방대한 데이터도 한 몫했다. NEST 엔진은 수 분 혹은 수 시간 단위의 말 덩어리도 학습할 수 있도록 구현됐다. 수 초 단위의 짧은 형태의 음성이 있어야 원활하게 학습할 수 있는 기존 엔진과 다른 점이다. 네이버가 보유한 방대한 뉴스 데이터가 NEST 엔진의 요긴한 학습 데이터로 쓰인 셈이다. \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBijhIK7nSd3",
        "colab_type": "text"
      },
      "source": [
        "**3.이미지 : 얼굴인식 (페이스북)**\n",
        "===\n",
        "ㄴ알\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbhWXKQMn-0-",
        "colab_type": "text"
      },
      "source": [
        "# **4.자율주행 : 테슬라,구글?**\n",
        "테스트\n",
        "\n"
      ]
    }
  ]
}